{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP techniques \n",
    "\n",
    "* Bag of Words \n",
    "* bigram, trigram, ngram, skipgram\n",
    "* TF-IDF 1972\n",
    "* Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "```python\n",
    "# Define the input sentences\n",
    "sentences = [\"I love coding\", \"Coding is fun\", \"Python is awesome\"]\n",
    "\n",
    "# Initialize an empty dictionary to store the word counts\n",
    "word_counts = {}\n",
    "\n",
    "# Iterate over each sentence\n",
    "for sentence in sentences:\n",
    "    # Split the sentence into words\n",
    "    words = sentence.split()\n",
    "    \n",
    "    # Iterate over each word\n",
    "    for word in words:\n",
    "        # Check if the word is already in the dictionary\n",
    "        if word in word_counts:\n",
    "            # If yes, increment the count by 1\n",
    "            word_counts[word] += 1\n",
    "        else:\n",
    "            # If no, add the word to the dictionary with count 1\n",
    "            word_counts[word] = 1\n",
    "\n",
    "# Print the word counts\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "```\n",
    "This code implements the bag of words technique by counting the occurrences of each word in the input sentences. It splits each sentence into words, and then iterates over each word to update the word counts in a dictionary. Finally, it prints the word counts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 1\n",
      "love: 1\n",
      "coding: 2\n",
      "is: 2\n",
      "fun.: 1\n",
      "Python: 1\n",
      "awesome: 1\n",
      "and: 1\n",
      "fun: 1\n"
     ]
    }
   ],
   "source": [
    "# Define the input sentences\n",
    "sentences = [\"I love coding\", \"Coding is fun.\", \"Python is awesome and fun\"]\n",
    "\n",
    "#  an empty dictionary to store the word counts\n",
    "word_counts = {}\n",
    "\n",
    "# Iterate oInitializever each sentence\n",
    "for sentence in sentences:\n",
    "    # Split the sentence into words\n",
    "    words = sentence.split()\n",
    "    \n",
    "    # Iterate over each word\n",
    "    for word in words:\n",
    "        # Check if the word is already in the dictionary\n",
    "        if word.lower() in word_counts:\n",
    "            # If yes, increment the count by 1\n",
    "            word_counts[word.lower()] += 1\n",
    "        else:\n",
    "            # If no, add the word to the dictionary with count 1\n",
    "            word_counts[word] = 1\n",
    "\n",
    "# Print the word counts\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Word  Count\n",
      "0        I      1\n",
      "1     love      1\n",
      "2   coding      2\n",
      "3       is      2\n",
      "4     fun.      1\n",
      "5   Python      1\n",
      "6  awesome      1\n",
      "7      and      1\n",
      "8      fun      1\n",
      "9      unk      1\n"
     ]
    }
   ],
   "source": [
    "# create a dataframe from wordcounts\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(list(word_counts.items()), columns = ['Word', 'Count'])\n",
    "# print(df)\n",
    "# add a row unk for word with count 1\n",
    "df.loc[len(df.index)] = ['unk', 1]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   I  love  coding  is  fun.  Python  awesome  and  fun\n",
      "0  0     1       1   0     0       0        0    0    0\n",
      "1  0     0       1   1     1       0        0    0    0\n",
      "2  0     0       0   1     0       0        1    1    1\n"
     ]
    }
   ],
   "source": [
    "# modify the dataframe to do the following\n",
    "# convert the word counts to column. \n",
    "# add sentences as rows \n",
    "# fill the dataframe with the word counts for each sentence\n",
    "# fill the missing values with 0\n",
    "# print the dataframe\n",
    "\n",
    "# create a new dataframe\n",
    "df1 = pd.DataFrame(columns = list(word_counts.keys()))\n",
    "\n",
    "# iterate over each sentence\n",
    "\n",
    "for sentence in sentences:\n",
    "    # split the sentence into words\n",
    "    words = sentence.split()\n",
    "    \n",
    "    # create a dictionary to store the word counts for the sentence\n",
    "    sentence_word_counts = {}\n",
    "    \n",
    "    # iterate over each word\n",
    "    for word in words:\n",
    "        # check if the word is already in the dictionary\n",
    "        if word.lower() in sentence_word_counts:\n",
    "            # if yes, increment the count by 1\n",
    "            sentence_word_counts[word.lower()] += 1\n",
    "        else:\n",
    "            # if no, add the word to the dictionary with count 1\n",
    "            sentence_word_counts[word.lower()] = 1\n",
    "    \n",
    "    # add the sentence to the dataframe\n",
    "    df1.loc[len(df1.index)] = sentence_word_counts\n",
    "\n",
    "df1.fillna(0, inplace=True)\n",
    "df1 = df1.astype(int)\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer in scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love coding', 'Coding is fun.', 'Python is awesome and fun']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   and  awesome  coding  fun  i  is  love  python\n",
      "0    0        0       1    0  1   0     1       0\n",
      "1    0        0       1    1  0   1     0       0\n",
      "2    1        1       0    1  0   1     0       1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>awesome</th>\n",
       "      <th>coding</th>\n",
       "      <th>fun</th>\n",
       "      <th>i</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>python</th>\n",
       "      <th>Unk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  awesome  coding  fun  i  is  love  python  Unk\n",
       "0    0        0       1    0  1   0     1       0    0\n",
       "1    0        0       1    1  0   1     0       0    0\n",
       "2    1        1       0    1  0   1     0       1    0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use count vectorizer to do the same\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# create an instance of CountVectorizer\n",
    "# use pattern to consider singe character words\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=True, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "\n",
    "# fit the vectorizer on the sentences\n",
    "vectorizer.fit(sentences)\n",
    "\n",
    "# transform the sentences to a matrix\n",
    "X = vectorizer.transform(sentences)\n",
    "\n",
    "# create a dataframe from the matrix\n",
    "df2 = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "print(df2)\n",
    "\n",
    "df2['Unk'] = 0\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " write 2 sentences wiht same words but different order having differnt meaning\n",
    "* \"The cat chased the dog eagerly.\"\n",
    "* \"Eagerly, the dog chased the cat.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram, Tri GRam and N gram \n",
    "\n",
    "Sentence: \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "```\n",
    "## Bigrams:\n",
    "(The, quick)\n",
    "(quick, brown)\n",
    "(brown, fox)\n",
    "(fox, jumps)\n",
    "(jumps, over)\n",
    "(over, the)\n",
    "(the, lazy)\n",
    "(lazy, dog)\n",
    "```\n",
    "\n",
    "##Trigrams:\n",
    "```\n",
    "(The, quick, brown)\n",
    "(quick, brown, fox)\n",
    "(brown, fox, jumps)\n",
    "(fox, jumps, over)\n",
    "(jumps, over, the)\n",
    "(over, the, lazy)\n",
    "(the, lazy, dog)\n",
    "```\n",
    "\n",
    "## 4-grams (4-grams or quadgrams):\n",
    "```\n",
    "(The, quick, brown, fox)\n",
    "(quick, brown, fox, jumps)\n",
    "(brown, fox, jumps, over)\n",
    "(fox, jumps, over, the)\n",
    "(jumps, over, the, lazy)\n",
    "(over, the, lazy, dog)\n",
    "```\n",
    "\n",
    "Sentence: \"I love to eat pizza with extra cheese.\"\n",
    "\n",
    "Bigrams:\n",
    "(I, love)\n",
    "(love, to)\n",
    "(to, eat)\n",
    "(eat, pizza)\n",
    "(pizza, with)\n",
    "(with, extra)\n",
    "(extra, cheese)\n",
    "Trigrams:\n",
    "(I, love, to)\n",
    "(love, to, eat)\n",
    "(to, eat, pizza)\n",
    "(eat, pizza, with)\n",
    "(pizza, with, extra)\n",
    "(with, extra, cheese)\n",
    "4-grams:\n",
    "(I, love, to, eat)\n",
    "(love, to, eat, pizza)\n",
    "(to, eat, pizza, with)\n",
    "(eat, pizza, with, extra)\n",
    "(pizza, with, extra, cheese)\n",
    "Explanation:\n",
    "Bigrams: Sequential pairs of words in the sentence.\n",
    "Trigrams: Sequential triplets of words in the sentence.\n",
    "N-grams: Sequential sequences of n words in the sentence.\n",
    "Each level (bigram, trigram, n-gram) provides increasingly more context about the sequence of words in the sentence, which is useful in various natural language processing tasks such as language modeling, text generation, and machine translation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary =  # number of unique words in the dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   and fun  awesome and  coding is  i love  is awesome  is fun  love coding  \\\n",
      "0        0            0          0       1           0       0            1   \n",
      "1        0            0          1       0           0       1            0   \n",
      "2        1            1          0       0           1       0            0   \n",
      "\n",
      "   python is  \n",
      "0          0  \n",
      "1          0  \n",
      "2          1  \n"
     ]
    }
   ],
   "source": [
    "# Create bigram features using CountVectorizer\n",
    "vectorizer = CountVectorizer(lowercase=True, ngram_range=(2,2), token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "\n",
    "# fit the vectorizer on the sentences\n",
    "vectorizer.fit(sentences)\n",
    "\n",
    "# transform the sentences to a matrix\n",
    "X = vectorizer.transform(sentences)\n",
    "\n",
    "# create a dataframe from the matrix\n",
    "df3 = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "print(df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   and  and fun  awesome  awesome and  coding  coding is  fun  i  i love  is  \\\n",
      "0    0        0        0            0       1          0    0  1       1   0   \n",
      "1    0        0        0            0       1          1    1  0       0   1   \n",
      "2    1        1        1            1       0          0    1  0       0   1   \n",
      "\n",
      "   is awesome  is fun  love  love coding  python  python is  \n",
      "0           0       0     1            1       0          0  \n",
      "1           0       1     0            0       0          0  \n",
      "2           1       0     0            0       1          1  \n"
     ]
    }
   ],
   "source": [
    "# Create bigram features using CountVectorizer\n",
    "vectorizer = CountVectorizer(lowercase=True, ngram_range=(1,2), token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "\n",
    "# fit the vectorizer on the sentences\n",
    "vectorizer.fit(sentences)\n",
    "\n",
    "# transform the sentences to a matrix\n",
    "X = vectorizer.transform(sentences)\n",
    "\n",
    "# create a dataframe from the matrix\n",
    "df3 = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "print(df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   and fun  awesome and  awesome and fun  coding is  coding is fun  i love  \\\n",
      "0        0            0                0          0              0       1   \n",
      "1        0            0                0          1              1       0   \n",
      "2        1            1                1          0              0       0   \n",
      "\n",
      "   i love coding  is awesome  is awesome and  is fun  love coding  python is  \\\n",
      "0              1           0               0       0            1          0   \n",
      "1              0           0               0       1            0          0   \n",
      "2              0           1               1       0            0          1   \n",
      "\n",
      "   python is awesome  \n",
      "0                  0  \n",
      "1                  0  \n",
      "2                  1  \n"
     ]
    }
   ],
   "source": [
    "# Create bigram features using CountVectorizer\n",
    "vectorizer = CountVectorizer(lowercase=True, ngram_range=(2,3), token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "\n",
    "# fit the vectorizer on the sentences\n",
    "vectorizer.fit(sentences)\n",
    "\n",
    "# transform the sentences to a matrix\n",
    "X = vectorizer.transform(sentences)\n",
    "\n",
    "# create a dataframe from the matrix\n",
    "df3 = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "print(df3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity",
   "language": "python",
   "name": "udacity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
